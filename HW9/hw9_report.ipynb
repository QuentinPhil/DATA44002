{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW9 - Email Classification\n",
        "### Quentin Phillips\n",
        "### DATA 440 Fall 2023\n",
        "### 12/19/23\n",
        "\n",
        "# Q1- Emails as .txt files\n",
        "\n",
        "#### The topic I chose to deem as relevant was emails regarding graduate school admissions. This included emails about the GRE, MSBA Program, or other Master's programs. Irrelevant emails included emails from class, piazza, advertisements, spams, investments, etc.\n"
      ],
      "metadata": {
        "id": "Us6ergXbmn9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2 - Naive Bayes Classification\n",
        "\n",
        "#### After coding the classifier to accept the training data, I ran the classification algorithm on the testing data and got this output:\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1S7DUHThliDCdF6UH7AIuWO6sU6K24ucB)\n",
        "\n",
        "#### So the results table would look like:\n",
        "\n",
        "| | |Email Table| |\n",
        "|---|---|---|---|\n",
        "|| |**Classification**|**Actual**|\n",
        "| |email1|Relevant|Relevant|\n",
        "| |email2|Relevant|Relevant|\n",
        "| |email3|Relevant|Relevant|\n",
        "| |email4|Relevant|Relevant|\n",
        "| |email5|Relevant|Relevant|\n",
        "| |email6|Relevant|Irelevant|\n",
        "| |email7|Relevant|Irelevant|\n",
        "| |email8|Relevant|Irelevant|\n",
        "| |email9|Relevant|Irelevant|\n",
        "| |email10|Irrelevant|Irelevant|\n",
        "\n",
        "##A\n",
        "\n",
        "#### As is clear from the table, the classifier is biased toward type 1, or false positive errors. My intuition is that this is due to most of my emails being vaguely college related, or at least targeted towards a college student, even if they aren't about graduate school specifically. This means many of the relevant and irrelevant emails have similar context. If I used a more distinct category as relevant, I think the classifier would have a higher accuracy coefficient.\n"
      ],
      "metadata": {
        "id": "Qvx0Gb-ganvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3 - Confusion Matrix\n",
        "\n",
        "#### Here is a confusion matrix of the results:\n",
        "\n",
        "|   |   |   |   |\n",
        "|---|---|---|---|\n",
        "|||**Actual**|\n",
        "|||Relevant|Irrelevant|\n",
        "|**Predicted**|Relevant|5|4|\n",
        "||Irrelevant|0|1|"
      ],
      "metadata": {
        "id": "4DCl_jq5O4D6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A\n",
        "\n",
        "#### Based on these results, the classifier was 60% accurate with a clear bias towards type 1 errors.\n",
        "\n",
        "## B\n",
        "\n",
        "#### The type 1 errors here are preferable to type 2 errors, as it would be better to let spam into the inbox then to discard important messages that have been mislabeled as spam. In this sense, the bias towards classifying as relevant is desirable, although maybe a bit too strong. This classifyer having 0 type 2 errors is very good.\n"
      ],
      "metadata": {
        "id": "MNEb_1uDNtjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q4\n",
        "\n",
        "#### For the precision score I used the formula:\n",
        "\n",
        "### TP/(TP+FP)\n",
        "\n",
        "#### This works out to:\n",
        "\n",
        "### 5/(5+4) = **5/9**\n",
        "\n",
        "#### For the recall score I used the formula:\n",
        "\n",
        "### TP/(TP+FN)\n",
        "\n",
        "#### With my model the numbers are:\n",
        "\n",
        "### 5/(5+0) = **1**\n",
        "\n",
        "#### For this particular model, it is good that the recall is closer to 1 than the precision, although it would be preferable for the precision to be improved as well."
      ],
      "metadata": {
        "id": "qR4hjdxMNSb0"
      }
    }
  ]
}